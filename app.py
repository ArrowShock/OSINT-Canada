import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin, urlparse, unquote
import io
import zipfile
import urllib3
import time
import pandas as pd

# --- ğŸ¤« å±è”½ SSL è­¦å‘Š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨", layout="wide", page_icon="ğŸ•µï¸")

# --- CSS ç¾åŒ– ---
st.markdown("""
    <style>
    .stButton>button { width: 100%; min-height: 50px; font-size: 16px; font-weight: 600; }
    .feature-tag { 
        display: inline-block; 
        padding: 4px 12px; 
        border-radius: 20px; 
        background-color: #f0f2f6; 
        color: #31333F; 
        font-size: 0.85em; 
        margin-right: 8px; 
        margin-bottom: 8px;
        border: 1px solid #d6d6d8;
    }
    </style>
""", unsafe_allow_html=True)

# --- è¾…åŠ©å‡½æ•° ---
def get_ext(filename):
    base, ext = os.path.splitext(filename)
    if not ext: return ".unknown"
    return ext.lower()

def is_target_file(href):
    valid_exts = ['.pdf', '.xlsx', '.xls', '.csv', '.docx', '.doc', '.zip', '.json', '.xml', '.txt', '.png', '.jpg']
    return any(href.lower().endswith(ext) for ext in valid_exts) or 'download' in href.lower()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ•µï¸ OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨")

# åŠŸèƒ½ Highlights
st.markdown("""
    <span class="feature-tag">âœ¨ æ— éœ€å®‰è£… Python</span>
    <span class="feature-tag">ğŸ“‚ æ”¯æŒ PDF/Excel/Word ç­‰å¤šç§æ ¼å¼</span>
    <span class="feature-tag">ğŸ“Š è¡¨æ ¼çº§ç­›é€‰ & æ’åº</span>
    <span class="feature-tag">ğŸš€ ä¸“ä¸º OSINT é•¿æœŸè¿½è¸ªè®¾è®¡</span>
""", unsafe_allow_html=True)

st.caption("è¾“å…¥ç½‘å€ -> æ™ºèƒ½æ‰«æ -> åƒ Excel ä¸€æ ·å‹¾é€‰éœ€è¦çš„æ–‡ä»¶ (æ”¯æŒå¢é‡ä¸‹è½½) -> ä¸€é”®æ‰“åŒ…")
st.markdown("---")

target_url = st.text_input("ğŸ”— è¾“å…¥ç›®æ ‡ç½‘å€:", placeholder="https://...")

# åˆå§‹åŒ– Session State
if 'found_files' not in st.session_state: st.session_state['found_files'] = []
if 'select_all' not in st.session_state: st.session_state['select_all'] = False 

# --- 1. æ‰«æé€»è¾‘ ---
if st.button("ğŸ” 1. æ‰«ææ–‡ä»¶åˆ—è¡¨"):
    if not target_url:
        st.warning("è¯·å…ˆè¾“å…¥ç½‘å€ï¼")
    else:
        try:
            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
            with st.spinner("æ­£åœ¨äº‘ç«¯æ‰«æ..."):
                response = requests.get(target_url, headers=headers, verify=False)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                files = []
                seen_urls = set()
                
                for a_tag in soup.find_all('a', href=True):
                    href = a_tag['href']
                    full_url = urljoin(target_url, href)
                    if full_url in seen_urls: continue
                    
                    if is_target_file(href):
                        seen_urls.add(full_url)
                        raw_name = os.path.basename(unquote(urlparse(full_url).path))
                        if '.' not in raw_name[-5:]: 
                            if 'pdf' in href.lower(): raw_name += '.pdf'
                            else: raw_name += '.html'
                        
                        link_text = a_tag.get_text(strip=True)
                        display_name = link_text if len(link_text) > 3 else raw_name
                        
                        files.append({
                            "ä¸‹è½½?": False, # é»˜è®¤åˆå§‹çŠ¶æ€
                            "æ–‡ä»¶å": display_name,
                            "ç±»å‹": get_ext(raw_name).upper().replace(".", ""),
                            "åŸå§‹æ–‡ä»¶å": raw_name,
                            "URL": full_url
                        })
                
                st.session_state['found_files'] = files
                st.session_state['select_all'] = False # é‡ç½®å…¨é€‰çŠ¶æ€
                st.success(f"æ‰«æå®Œæˆï¼å‘ç° {len(files)} ä¸ªæ–‡ä»¶ã€‚")
                
        except Exception as e:
            st.error(f"æ‰«æå¤±è´¥: {e}")

# --- 2. è¡¨æ ¼æ“ä½œåŒº ---
if st.session_state['found_files']:
    st.markdown("---")
    st.subheader("2ï¸âƒ£ é€‰æ‹©ä¸ä¸‹è½½")
    
    # è½¬æ¢æ•°æ®ä¸º DataFrame
    df = pd.DataFrame(st.session_state['found_files'])
    
    # --- å…¨é€‰/å…¨ä¸é€‰ æŒ‰é’®é€»è¾‘ ---
    col_btn, col_info = st.columns([1, 4])
    with col_btn:
        # è¿™æ˜¯ä¸€ä¸ªåˆ‡æ¢æŒ‰é’®
        if st.button("âœ… å…¨é€‰ / â¬œ å…¨ä¸é€‰"):
            st.session_state['select_all'] = not st.session_state['select_all']
    
    # æ ¹æ®æŒ‰é’®çŠ¶æ€ï¼Œå¼ºåˆ¶æ›´æ–° DataFrame çš„å‹¾é€‰çŠ¶æ€
    if st.session_state['select_all']:
        df["ä¸‹è½½?"] = True
    else:
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸å¼ºåˆ¶è®¾ä¸º Falseï¼Œå¦åˆ™ç”¨æˆ·æ‰‹åŠ¨å‹¾é€‰çš„ä¼šè¢«å†²æ‰
        # åªæœ‰åœ¨åˆšç‚¹å‡»â€œå…¨ä¸é€‰â€çš„é‚£ä¸€ç¬é—´å¯èƒ½éœ€è¦é‡ç½®ï¼Œä½†åœ¨ Streamlit é‡Œ
        # æœ€ç®€å•çš„é€»è¾‘æ˜¯ï¼šå¦‚æœç”¨æˆ·æƒ³å…¨é€‰ï¼Œç‚¹æŒ‰é’®ï¼›å¦‚æœæƒ³å¾®è°ƒï¼Œç›´æ¥åœ¨è¡¨æ ¼é‡Œç‚¹ã€‚
        # ä¸ºäº†æ–¹ä¾¿ï¼Œè¿™é‡Œè®¾å®šï¼šç‚¹å‡»æŒ‰é’® -> å˜ä¸ºå…¨é€‰ï¼›å†ç‚¹ -> å˜ä¸ºå…¨é€‰å–æ¶ˆï¼ˆå›åˆ°åˆå§‹è¡¨æ ¼ï¼‰
        pass

    # å¦‚æœæ˜¯â€œå…¨é€‰â€æ¨¡å¼ï¼Œè¦†ç›–æ•°æ®ï¼›å¦åˆ™ä½¿ç”¨ data_editor çš„é»˜è®¤ç¼–è¾‘èƒ½åŠ›
    if st.session_state['select_all']:
        df["ä¸‹è½½?"] = True
        
    # æ˜¾ç¤ºè¡¨æ ¼
    edited_df = st.data_editor(
        df,
        column_config={
            "ä¸‹è½½?": st.column_config.CheckboxColumn("ä¸‹è½½?", width="small"),
            "URL": st.column_config.LinkColumn("é“¾æ¥"),
        },
        disabled=["æ–‡ä»¶å", "ç±»å‹", "åŸå§‹æ–‡ä»¶å", "URL"],
        hide_index=True,
        use_container_width=True,
        height=400,
        key="editor" # èµ‹äºˆå”¯ä¸€ key
    )
    
    # ç»Ÿè®¡é€‰ä¸­é¡¹
    selected_rows = edited_df[edited_df["ä¸‹è½½?"] == True]
    count = len(selected_rows)
    
    with col_info:
        if st.session_state['select_all']:
            st.info(f"âš¡ å·²å¯ç”¨å…¨é€‰æ¨¡å¼ã€‚å½“å‰é€‰ä¸­: {count} ä¸ªæ–‡ä»¶")
        else:
            st.info(f"å½“å‰é€‰ä¸­: {count} ä¸ªæ–‡ä»¶ (ç‚¹å‡»å·¦ä¾§æŒ‰é’®å¯ä¸€é”®å…¨é€‰)")

    # 3. ä¸‹è½½æŒ‰é’®
    if st.button(f"ğŸ“¦ å¼€å§‹æ‰“åŒ…ä¸‹è½½ ({count} ä¸ªæ–‡ä»¶)"):
        if count == 0:
            st.warning("âš ï¸ è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ–‡ä»¶ï¼")
        else:
            zip_buffer = io.BytesIO()
            headers = {"User-Agent": "Mozilla/5.0"}
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            download_list = selected_rows.to_dict('records')
            total = len(download_list)
            success_count = 0
            
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for i, item in enumerate(download_list):
                    try:
                        status_text.text(f"æ­£åœ¨ä¸‹è½½ ({i+1}/{total}): {item['åŸå§‹æ–‡ä»¶å']}...")
                        r = requests.get(item['URL'], headers=headers, verify=False, timeout=60)
                        zf.writestr(item['åŸå§‹æ–‡ä»¶å'], r.content)
                        success_count += 1
                        time.sleep(1)
                    except:
                        pass
                    progress_bar.progress((i + 1) / total)
            
            status_text.text("âœ… æ‰“åŒ…å®Œæˆï¼")
            progress_bar.empty()
            
            st.download_button(
                label=f"ğŸš€ ä¸‹è½½ ZIP åŒ… ({success_count} ä¸ªæ–‡ä»¶)",
                data=zip_buffer.getvalue(),
                file_name="OSINT_Files.zip",
                mime="application/zip",
                type="primary"
            )
