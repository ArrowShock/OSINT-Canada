import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin, urlparse, unquote
import io
import zipfile
import urllib3

# --- ğŸ¤« å±è”½ SSL è­¦å‘Š ---
# æ—¢ç„¶æˆ‘ä»¬å†³å®šå¿½ç•¥è¯ä¹¦ï¼Œå°±ä¸è¦è®©å®ƒä¸€ç›´å¼¹çº¢è‰²çš„è­¦å‘Šæ–‡å­—
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="OSINT äº‘ç«¯ä¸‹è½½å™¨", layout="wide", page_icon="ğŸ•µï¸")

# --- CSS ç¾åŒ– ---
st.markdown("""
    <style>
    .stButton>button { width: 100%; min-height: 60px; font-size: 18px; font-weight: 700; }
    .success-log { color: #0f5132; background-color: #d1e7dd; padding: 6px; border-radius: 4px; border-left: 4px solid #198754; margin-bottom: 2px; }
    .badge { display: inline-block; padding: 2px 6px; border-radius: 4px; font-size: 0.75em; color: white; margin-right: 8px; font-weight: bold; }
    .pdf-bg { background-color: #b30b00; }
    .xls-bg { background-color: #1d6f42; }
    .doc-bg { background-color: #2b579a; }
    .zip-bg { background-color: #e6a200; color: black; }
    .other-bg { background-color: #6c757d; }
    </style>
""", unsafe_allow_html=True)

# --- è¾…åŠ©å‡½æ•° ---
def get_file_type_badge(filename):
    ext = os.path.splitext(filename)[1].lower()
    if ext == '.pdf': return "<span class='badge pdf-bg'>PDF</span>"
    if ext in ['.xlsx', '.xls', '.csv']: return "<span class='badge xls-bg'>EXCEL</span>"
    if ext in ['.docx', '.doc']: return "<span class='badge doc-bg'>WORD</span>"
    if ext in ['.zip', '.rar']: return "<span class='badge zip-bg'>ZIP</span>"
    return f"<span class='badge other-bg'>{ext.upper()}</span>"

def is_target_file(href):
    valid_exts = ['.pdf', '.xlsx', '.xls', '.csv', '.docx', '.doc', '.zip', '.json', '.xml', '.txt']
    return any(href.lower().endswith(ext) for ext in valid_exts) or 'download' in href.lower()

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ•µï¸ OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨")
st.caption("è¾“å…¥ç½‘å€ -> æ‰«æ -> ç”Ÿæˆ ZIP åŒ…ä¸‹è½½ | æ— éœ€å®‰è£… Pythonï¼Œå‘ç»™æœ‹å‹ç›´æ¥ç”¨")
st.markdown("---")

target_url = st.text_input("ğŸ”— è¾“å…¥ç›®æ ‡ç½‘å€:", placeholder="https://...")

if 'found_files' not in st.session_state: st.session_state['found_files'] = []

# --- 1. æ‰«æ ---
if st.button("ğŸ” 1. æ‰«ææ–‡ä»¶åˆ—è¡¨"):
    if not target_url:
        st.warning("è¯·å…ˆè¾“å…¥ç½‘å€ï¼")
    else:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            with st.spinner("æ­£åœ¨äº‘ç«¯æ‰«æ..."):
                # å…³é”®ä¿®æ”¹ï¼šverify=False (å¿½ç•¥è¯ä¹¦éªŒè¯)
                response = requests.get(target_url, headers=headers, verify=False)
                response.raise_for_status() # æ£€æŸ¥æ˜¯å¦æ˜¯ 404
                soup = BeautifulSoup(response.text, 'html.parser')
                
                files = []
                seen_urls = set()
                
                for a_tag in soup.find_all('a', href=True):
                    href = a_tag['href']
                    full_url = urljoin(target_url, href)
                    if full_url in seen_urls: continue
                    
                    if is_target_file(href):
                        seen_urls.add(full_url)
                        raw_name = os.path.basename(unquote(urlparse(full_url).path))
                        if '.' not in raw_name[-5:]: raw_name += '.dat'
                        link_text = a_tag.get_text(strip=True)
                        display_name = link_text if len(link_text) > 3 else raw_name
                        files.append({"name": display_name, "url": full_url, "file": raw_name})
                
                st.session_state['found_files'] = files
                st.success(f"æ‰«æå®Œæˆï¼å‘ç° {len(files)} ä¸ªæ–‡ä»¶ã€‚")
                
        except Exception as e:
            st.error(f"æ‰«æå¤±è´¥: {e}")

# --- 2. æ‰“åŒ…ä¸‹è½½ ---
if st.session_state['found_files']:
    st.markdown("---")
    st.subheader(f"2ï¸âƒ£ å‡†å¤‡ä¸‹è½½ ({len(st.session_state['found_files'])})")
    
    with st.expander("ç‚¹å‡»æŸ¥çœ‹å³å°†ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨"):
        for item in st.session_state['found_files']:
            badge = get_file_type_badge(item['file'])
            st.markdown(f"<div>{badge} {item['name']}</div>", unsafe_allow_html=True)

    if st.button("ğŸ“¦ å¼€å§‹æ‰“åŒ…å¹¶ä¸‹è½½ ZIP"):
        zip_buffer = io.BytesIO()
        headers = {"User-Agent": "Mozilla/5.0"}
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            total = len(st.session_state['found_files'])
            success_count = 0
            
            for i, item in enumerate(st.session_state['found_files']):
                try:
                    status_text.text(f"æ­£åœ¨ä¸‹è½½: {item['file']}...")
                    # å…³é”®ä¿®æ”¹ï¼šverify=False (å¿½ç•¥è¯ä¹¦éªŒè¯)
                    r = requests.get(item['url'], headers=headers, verify=False)
                    zf.writestr(item['file'], r.content)
                    success_count += 1
                except:
                    pass
                progress_bar.progress((i + 1) / total)
        
        status_text.text("æ‰“åŒ…å®Œæˆï¼")
        progress_bar.empty()
        
        st.download_button(
            label=f"ğŸš€ ç‚¹å‡»ä¸‹è½½ ZIP å‹ç¼©åŒ… ({success_count} ä¸ªæ–‡ä»¶)",
            data=zip_buffer.getvalue(),
            file_name="OSINT_Files.zip",
            mime="application/zip",
            type="primary"
        )
