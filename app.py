import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin, urlparse, unquote
import io
import zipfile
import urllib3
import time
import pandas as pd

# --- ğŸ¤« å±è”½ SSL è­¦å‘Š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨", layout="wide", page_icon="ğŸ•µï¸")

# --- ğŸ¨ CSS ---
st.markdown("""
    <style>
    .block-container { padding-top: 2rem !important; padding-bottom: 1rem !important; }
    h1 { margin-bottom: 0.5rem !important; }
    .compact-divider { border-top: 1px solid #e6e6e6; margin-top: 10px; margin-bottom: 15px; }
    .step-header { font-size: 22px; font-weight: 700; color: #0f52ba; margin-bottom: 10px; }
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .feature-tag { 
        display: inline-block; padding: 3px 10px; border-radius: 15px; 
        background-color: #f0f2f6; color: #444; font-size: 0.8em; 
        margin-right: 6px; border: 1px solid #ddd;
    }
    </style>
""", unsafe_allow_html=True)

# --- è¾…åŠ©å‡½æ•° ---
def get_ext(filename):
    base, ext = os.path.splitext(filename)
    if not ext: return ".unknown"
    return ext.lower()

def is_target_file(href):
    valid_exts = ['.pdf', '.xlsx', '.xls', '.csv', '.docx', '.doc', '.zip', '.json', '.xml', '.txt', '.png', '.jpg']
    return any(href.lower().endswith(ext) for ext in valid_exts) or 'download' in href.lower()

def get_file_size_mb(url):
    try:
        response = requests.head(url, verify=False, timeout=5)
        size_bytes = int(response.headers.get('Content-Length', 0))
        return size_bytes / (1024 * 1024)
    except:
        return 0

# å›è°ƒï¼šé‡ç½®é€»è¾‘
def reset_callback():
    if 'found_files' in st.session_state:
        for f in st.session_state['found_files']:
            f['ä¸‹è½½?'] = False
    st.session_state.batch_start = 1
    st.session_state.batch_end = 1

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ•µï¸ OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨")

st.markdown("""
    <div style="margin-bottom: 10px;">
        <span class="feature-tag">ğŸ›¡ï¸ æ™ºèƒ½é˜²å´©æºƒ (è‡ªåŠ¨è·³è¿‡å¤§æ–‡ä»¶)</span>
        <span class="feature-tag">ğŸ“‚ æ”¯æŒå¤šç§æ ¼å¼</span>
        <span class="feature-tag">ğŸ”„ åŒå‘åŒæ­¥é€‰æ‹©</span>
    </div>
    <div class="compact-divider"></div> 
""", unsafe_allow_html=True)

if 'found_files' not in st.session_state: st.session_state['found_files'] = []

# --- Step 1 ---
st.markdown('<div class="step-header">Step 1. æ‰«ææ–‡ä»¶åˆ—è¡¨</div>', unsafe_allow_html=True)

col_input, col_btn = st.columns([3, 1], vertical_alignment="bottom")
with col_input:
    target_url = st.text_input("URL", placeholder="è¾“å…¥ç½‘å€...", label_visibility="collapsed")
with col_btn:
    start_scan = st.button("ğŸš€ å¼€å§‹æ‰«æ", type="secondary", use_container_width=True)

if start_scan:
    if not target_url:
        st.warning("è¯·å…ˆè¾“å…¥ç½‘å€ï¼")
    else:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            with st.spinner("æ­£åœ¨æ‰«æ..."):
                response = requests.get(target_url, headers=headers, verify=False)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                files = []
                seen_urls = set()
                
                for a_tag in soup.find_all('a', href=True):
                    href = a_tag['href']
                    full_url = urljoin(target_url, href)
                    if full_url in seen_urls: continue
                    
                    if is_target_file(href):
                        seen_urls.add(full_url)
                        raw_name = os.path.basename(unquote(urlparse(full_url).path))
                        if '.' not in raw_name[-5:]: 
                            if 'pdf' in href.lower(): raw_name += '.pdf'
                            else: raw_name += '.html'
                        
                        link_text = a_tag.get_text(strip=True)
                        display_name = link_text if len(link_text) > 3 else raw_name
                        
                        files.append({
                            "ä¸‹è½½?": False,
                            "åºå·": len(files) + 1,
                            "æ–‡ä»¶å": display_name,
                            "åŸå§‹æ–‡ä»¶å": raw_name,
                            "URL": full_url
                        })
                
                st.session_state['found_files'] = files
                st.toast(f"æ‰«æå®Œæˆï¼å‘ç° {len(files)} ä¸ªæ–‡ä»¶ã€‚", icon="âœ…")
                
        except Exception as e:
            st.error(f"æ‰«æå¤±è´¥: {e}")

# --- Step 2 ---
if st.session_state['found_files']:
    st.markdown('<div class="compact-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">Step 2. é€‰æ‹©ä¸ä¸‹è½½</div>', unsafe_allow_html=True)
    
    # === æ™ºèƒ½é€‰æ‹©å™¨ ===
    with st.container():
        # ç¡®ä¿ session state åˆå§‹åŒ–
        if 'batch_start' not in st.session_state: st.session_state.batch_start = 1
        if 'batch_end' not in st.session_state: st.session_state.batch_end = min(len(st.session_state['found_files']), 30)

        c1, c2, c3, c4 = st.columns([1, 1, 1.5, 3], vertical_alignment="bottom")
        
        with c1: 
            start_id = st.number_input("èµ·å§‹ ID", min_value=1, key="batch_start")
        with c2: 
            end_id = st.number_input("ç»“æŸ ID", min_value=1, key="batch_end")
            
        with c3:
            if st.button("âœ… ä»…é€‰ä¸­æ­¤èŒƒå›´", help="å–æ¶ˆå…¶ä»–ï¼Œåªé€‰å½“å‰"):
                for f in st.session_state['found_files']:
                    if start_id <= f['åºå·'] <= end_id:
                        f['ä¸‹è½½?'] = True
                    else:
                        f['ä¸‹è½½?'] = False
                st.toast(f"å·²é€‰ä¸­ {start_id}-{end_id}", icon="âš¡")

        with c4:
             st.button("ğŸ—‘ï¸ é‡ç½®æ‰€æœ‰", on_click=reset_callback)

    # === è¡¨æ ¼åŒºåŸŸ ===
    df = pd.DataFrame(st.session_state['found_files'])
    
    # æ ¸å¿ƒä¿®æ”¹ï¼šæ¥æ”¶è¡¨æ ¼çš„å³æ—¶ä¿®æ”¹
    edited_df = st.data_editor(
        df,
        column_config={
            "ä¸‹è½½?": st.column_config.CheckboxColumn("é€‰?", width="small"),
            "åºå·": st.column_config.NumberColumn("No.", width="small", format="%d"),
            "URL": st.column_config.LinkColumn("é“¾æ¥"),
        },
        disabled=["åºå·", "æ–‡ä»¶å", "åŸå§‹æ–‡ä»¶å", "URL"],
        hide_index=True,
        use_container_width=True,
        height=400,
        key="editor"
    )
    
    # --- ğŸ”„ åŒå‘åŒæ­¥é€»è¾‘ (Magic Happens Here) ---
    # 1. ç«‹å³æŠŠè¡¨æ ¼çš„æ‰‹åŠ¨ä¿®æ”¹å­˜å› Session State
    st.session_state['found_files'] = edited_df.to_dict('records')
    
    # 2. æ£€æŸ¥æ˜¯å¦æœ‰é€‰ä¸­é¡¹ï¼Œå¹¶åå‘æ›´æ–°è¾“å…¥æ¡†
    selected_indices = [f['åºå·'] for f in st.session_state['found_files'] if f['ä¸‹è½½?']]
    
    if selected_indices:
        real_min = min(selected_indices)
        real_max = max(selected_indices)
        
        # 3. å¦‚æœå‘ç°è¾“å…¥æ¡†çš„æ•°å­—å’Œå®é™…å‹¾é€‰çš„ä¸ä¸€æ ·ï¼Œå¼ºåˆ¶åˆ·æ–°è¾“å…¥æ¡†
        if real_min != st.session_state.batch_start or real_max != st.session_state.batch_end:
            st.session_state.batch_start = int(real_min)
            st.session_state.batch_end = int(real_max)
            st.rerun() # ğŸš€ è§¦å‘åˆ·æ–°ï¼Œè®©æ‚¨çœ‹åˆ°è¾“å…¥æ¡†æ•°å­—è‡ªåŠ¨å˜äº†ï¼

    # --- ä¸‹è½½åŒºåŸŸ ---
    selected_rows = [f for f in st.session_state['found_files'] if f['ä¸‹è½½?']]
    count = len(selected_rows)
    
    st.info(f"å½“å‰é€‰ä¸­: {count} ä¸ªæ–‡ä»¶")

    if st.button(f"ğŸ“¦ å®‰å…¨ä¸‹è½½ ({count} ä¸ªæ–‡ä»¶)", type="primary"):
        if count == 0:
            st.warning("è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ–‡ä»¶ï¼")
        else:
            zip_buffer = io.BytesIO()
            headers = {"User-Agent": "Mozilla/5.0"}
            progress_bar = st.progress(0)
            status_text = st.empty()
            error_log = []
            
            total = len(selected_rows)
            success_count = 0
            
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for i, item in enumerate(selected_rows):
                    try:
                        file_mb = get_file_size_mb(item['URL'])
                        
                        if file_mb > 100: 
                            status_text.warning(f"âš ï¸ è·³è¿‡å¤§æ–‡ä»¶ ({file_mb:.1f}MB): {item['åŸå§‹æ–‡ä»¶å']}")
                            error_log.append(f"è·³è¿‡(å¤ªå¤§): {item['åŸå§‹æ–‡ä»¶å']}")
                            time.sleep(0.5)
                            continue
                        
                        status_text.text(f"ä¸‹è½½ä¸­ ({i+1}/{total}): {item['åŸå§‹æ–‡ä»¶å']}...")
                        r = requests.get(item['URL'], headers=headers, verify=False, timeout=60)
                        zf.writestr(item['åŸå§‹æ–‡ä»¶å'], r.content)
                        success_count += 1
                        time.sleep(1)
                    except Exception as e:
                        error_log.append(f"å¤±è´¥: {item['åŸå§‹æ–‡ä»¶å']}")
                        pass
                    progress_bar.progress((i + 1) / total)
            
            status_text.success(f"å®Œæˆï¼æˆåŠŸ: {success_count}, è·³è¿‡/å¤±è´¥: {len(error_log)}")
            if error_log:
                st.warning("ä»¥ä¸‹æ–‡ä»¶æœªä¸‹è½½ï¼ˆå¯èƒ½å¤ªå¤§ï¼‰ï¼š")
                st.write(error_log)
            
            progress_bar.empty()
            
            if success_count > 0:
                st.download_button(
                    label=f"ğŸš€ ä¸‹è½½ ZIP ({success_count} ä¸ªæ–‡ä»¶)",
                    data=zip_buffer.getvalue(),
                    file_name=f"OSINT_Files_{int(time.time())}.zip",
                    mime="application/zip",
                    type="primary"
                )
