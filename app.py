import streamlit as st
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urljoin, urlparse, unquote
import io
import zipfile
import urllib3
import time
import pandas as pd

# --- ğŸ¤« å±è”½ SSL è­¦å‘Š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨", layout="wide", page_icon="ğŸ•µï¸")

# --- ğŸ¨ CSS ---
st.markdown("""
    <style>
    .block-container { padding-top: 2rem !important; padding-bottom: 1rem !important; }
    h1 { margin-bottom: 0.5rem !important; }
    .compact-divider { border-top: 1px solid #e6e6e6; margin-top: 10px; margin-bottom: 15px; }
    .step-header { font-size: 22px; font-weight: 700; color: #0f52ba; margin-bottom: 10px; }
    .stButton>button { width: 100%; border-radius: 8px; font-weight: bold; }
    .feature-tag { 
        display: inline-block; padding: 3px 10px; border-radius: 15px; 
        background-color: #f0f2f6; color: #444; font-size: 0.8em; 
        margin-right: 6px; border: 1px solid #ddd;
    }
    </style>
""", unsafe_allow_html=True)

# --- è¾…åŠ©å‡½æ•° ---
def get_ext(filename):
    base, ext = os.path.splitext(filename)
    if not ext: return ".unknown"
    return ext.lower()

def is_target_file(href):
    valid_exts = ['.pdf', '.xlsx', '.xls', '.csv', '.docx', '.doc', '.zip', '.json', '.xml', '.txt', '.png', '.jpg']
    return any(href.lower().endswith(ext) for ext in valid_exts) or 'download' in href.lower()

def get_file_size_mb(url):
    try:
        response = requests.head(url, verify=False, timeout=5)
        size_bytes = int(response.headers.get('Content-Length', 0))
        return size_bytes / (1024 * 1024)
    except:
        return 0

# --- æ ¸å¿ƒé€»è¾‘å‡½æ•° ---
def update_source_data(files):
    """æ›´æ–°æºæ•°æ®å¹¶ç¼“å­˜ DataFrameï¼Œé˜²æ­¢ä¸å¿…è¦çš„é‡ç»˜"""
    st.session_state['found_files'] = files
    # å…³é”®ï¼šç”Ÿæˆå›ºå®šçš„ DataFrame å¯¹è±¡ï¼Œé™¤éæ˜¾å¼æ›´æ–°ï¼Œå¦åˆ™ä¸å˜
    st.session_state['cached_df'] = pd.DataFrame(files)

def apply_range_selection():
    """æŒ‰é’®å›è°ƒï¼šæ›´æ–°èŒƒå›´"""
    start = st.session_state.batch_start
    end = st.session_state.batch_end
    
    # åªæœ‰ç‚¹å‡»æŒ‰é’®æ—¶ï¼Œæˆ‘ä»¬æ‰ä¿®æ”¹æºæ•°æ®
    for f in st.session_state['found_files']:
        if start <= f['åºå·'] <= end:
            f['ä¸‹è½½?'] = True
        else:
            f['ä¸‹è½½?'] = False
    
    # æ›´æ–°ç¼“å­˜
    update_source_data(st.session_state['found_files'])

def reset_all():
    """æŒ‰é’®å›è°ƒï¼šé‡ç½®"""
    for f in st.session_state['found_files']:
        f['ä¸‹è½½?'] = False
    st.session_state.batch_start = 1
    st.session_state.batch_end = 1
    update_source_data(st.session_state['found_files'])

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ•µï¸ OSINT äº‘ç«¯æ‰¹é‡ä¸‹è½½å™¨")

st.markdown("""
    <div style="margin-bottom: 10px;">
        <span class="feature-tag">ğŸ›¡ï¸ æ™ºèƒ½é˜²å´©æºƒ</span>
        <span class="feature-tag">ğŸ”„ åŒå‘åŒæ­¥</span>
        <span class="feature-tag">âš“ æ»šåŠ¨æ¡é˜²è·³åŠ¨ç‰ˆ</span>
    </div>
    <div class="compact-divider"></div> 
""", unsafe_allow_html=True)

if 'found_files' not in st.session_state: st.session_state['found_files'] = []
if 'cached_df' not in st.session_state: st.session_state['cached_df'] = pd.DataFrame()

# --- Step 1 ---
st.markdown('<div class="step-header">Step 1. æ‰«ææ–‡ä»¶åˆ—è¡¨</div>', unsafe_allow_html=True)

col_input, col_btn = st.columns([3, 1], vertical_alignment="bottom")
with col_input:
    target_url = st.text_input("URL", placeholder="è¾“å…¥ç½‘å€...", label_visibility="collapsed")
with col_btn:
    start_scan = st.button("ğŸš€ å¼€å§‹æ‰«æ", type="secondary", use_container_width=True)

if start_scan:
    if not target_url:
        st.warning("è¯·å…ˆè¾“å…¥ç½‘å€ï¼")
    else:
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            with st.spinner("æ­£åœ¨æ‰«æ..."):
                response = requests.get(target_url, headers=headers, verify=False)
                soup = BeautifulSoup(response.text, 'html.parser')
                
                files = []
                seen_urls = set()
                
                for a_tag in soup.find_all('a', href=True):
                    href = a_tag['href']
                    full_url = urljoin(target_url, href)
                    if full_url in seen_urls: continue
                    
                    if is_target_file(href):
                        seen_urls.add(full_url)
                        raw_name = os.path.basename(unquote(urlparse(full_url).path))
                        if '.' not in raw_name[-5:]: 
                            if 'pdf' in href.lower(): raw_name += '.pdf'
                            else: raw_name += '.html'
                        
                        link_text = a_tag.get_text(strip=True)
                        display_name = link_text if len(link_text) > 3 else raw_name
                        
                        files.append({
                            "ä¸‹è½½?": False,
                            "åºå·": len(files) + 1,
                            "æ–‡ä»¶å": display_name,
                            "åŸå§‹æ–‡ä»¶å": raw_name,
                            "URL": full_url
                        })
                
                update_source_data(files)
                st.toast(f"æ‰«æå®Œæˆï¼å‘ç° {len(files)} ä¸ªæ–‡ä»¶ã€‚", icon="âœ…")
                
        except Exception as e:
            st.error(f"æ‰«æå¤±è´¥: {e}")

# --- Step 2 ---
if not st.session_state['cached_df'].empty:
    st.markdown('<div class="compact-divider"></div>', unsafe_allow_html=True)
    st.markdown('<div class="step-header">Step 2. é€‰æ‹©ä¸ä¸‹è½½</div>', unsafe_allow_html=True)
    
    # === æ™ºèƒ½é€‰æ‹©å™¨ ===
    with st.container():
        if 'batch_start' not in st.session_state: st.session_state.batch_start = 1
        if 'batch_end' not in st.session_state: st.session_state.batch_end = min(len(st.session_state['found_files']), 30)

        c1, c2, c3, c4 = st.columns([1, 1, 1.5, 3], vertical_alignment="bottom")
        
        with c1: 
            st.number_input("èµ·å§‹ ID", min_value=1, key="batch_start")
        with c2: 
            st.number_input("ç»“æŸ ID", min_value=1, key="batch_end")
            
        with c3:
            st.button("âœ… ä»…é€‰ä¸­æ­¤èŒƒå›´", on_click=apply_range_selection, help="å–æ¶ˆå…¶ä»–ï¼Œåªé€‰å½“å‰")

        with c4:
             st.button("ğŸ—‘ï¸ é‡ç½®æ‰€æœ‰", on_click=reset_all)

    # === è¡¨æ ¼åŒºåŸŸ (é˜²è·³åŠ¨æ ¸å¿ƒ) ===
    # æˆ‘ä»¬ä¸å†åœ¨æ¯æ¬¡åˆ·æ–°æ—¶ç”Ÿæˆæ–°çš„ DataFrameï¼Œè€Œæ˜¯ä½¿ç”¨ session_state ä¸­çš„ç¼“å­˜
    # è¿™æ · data_editor ä¼šè®¤ä¸ºæ•°æ®æºæ²¡å˜ï¼Œä»è€Œå°½å¯èƒ½ä¿æŒæ»šåŠ¨ä½ç½®
    
    edited_df = st.data_editor(
        st.session_state['cached_df'], # <--- ä½¿ç”¨å›ºå®šç¼“å­˜
        column_config={
            "ä¸‹è½½?": st.column_config.CheckboxColumn("é€‰?", width="small"),
            "åºå·": st.column_config.NumberColumn("No.", width="small", format="%d"),
            "URL": st.column_config.LinkColumn("é“¾æ¥"),
        },
        disabled=["åºå·", "æ–‡ä»¶å", "åŸå§‹æ–‡ä»¶å", "URL"],
        hide_index=True,
        use_container_width=True,
        height=400,
        key="editor" 
        # æ³¨æ„ï¼šè¿™é‡Œå»æ‰äº† on_change å›è°ƒï¼Œé˜²æ­¢æ‰‹åŠ¨å‹¾é€‰æ—¶å› ä¸ºæ•°æ®æºæ›´æ–°å¯¼è‡´çš„è·³åŠ¨
    )
    
    # === åŒæ­¥é€»è¾‘ (Manual Sync) ===
    # è™½ç„¶å»æ‰äº†å›è°ƒï¼Œä½†æˆ‘ä»¬ä¾ç„¶éœ€è¦è¯»å–è¡¨æ ¼çš„æœ€æ–°çŠ¶æ€æ¥æ›´æ–°è¾“å…¥æ¡†
    # æˆ‘ä»¬åœ¨ä¸»æµç¨‹é‡Œè®¡ç®—ï¼Œå¦‚æœå‘ç°è¾“å…¥æ¡†éœ€è¦æ›´æ–°ï¼Œå†è§¦å‘ rerun
    
    selected_indices = edited_df[edited_df["ä¸‹è½½?"] == True]["åºå·"].tolist()
    
    if selected_indices:
        real_min = int(min(selected_indices))
        real_max = int(max(selected_indices))
        
        # åªæœ‰å½“æ•°å­—çœŸçš„éœ€è¦å˜çš„æ—¶å€™ï¼Œæ‰è§¦å‘åˆ·æ–°
        if real_min != st.session_state.batch_start or real_max != st.session_state.batch_end:
            st.session_state.batch_start = real_min
            st.session_state.batch_end = real_max
            st.rerun() 

    # --- ä¸‹è½½åŒºåŸŸ ---
    # ä¸‹è½½æ—¶ç›´æ¥ä½¿ç”¨ edited_dfï¼Œå®ƒæ˜¯ç”¨æˆ·å½“å‰çœ‹åˆ°çš„æœ€æ–°çŠ¶æ€ï¼ˆåŒ…å«æ‰‹åŠ¨å‹¾é€‰ï¼‰
    selected_rows = edited_df[edited_df["ä¸‹è½½?"] == True]
    count = len(selected_rows)
    
    st.info(f"å½“å‰é€‰ä¸­: {count} ä¸ªæ–‡ä»¶")

    if st.button(f"ğŸ“¦ å®‰å…¨ä¸‹è½½ ({count} ä¸ªæ–‡ä»¶)", type="primary"):
        if count == 0:
            st.warning("è¯·è‡³å°‘å‹¾é€‰ä¸€ä¸ªæ–‡ä»¶ï¼")
        else:
            zip_buffer = io.BytesIO()
            headers = {"User-Agent": "Mozilla/5.0"}
            progress_bar = st.progress(0)
            status_text = st.empty()
            error_log = []
            
            download_list = selected_rows.to_dict('records')
            total = len(download_list)
            success_count = 0
            
            with zipfile.ZipFile(zip_buffer, "w") as zf:
                for i, item in enumerate(download_list):
                    try:
                        file_mb = get_file_size_mb(item['URL'])
                        
                        if file_mb > 100: 
                            status_text.warning(f"âš ï¸ è·³è¿‡å¤§æ–‡ä»¶ ({file_mb:.1f}MB): {item['åŸå§‹æ–‡ä»¶å']}")
                            error_log.append(f"è·³è¿‡(å¤ªå¤§): {item['åŸå§‹æ–‡ä»¶å']}")
                            time.sleep(0.5)
                            continue
                        
                        status_text.text(f"ä¸‹è½½ä¸­ ({i+1}/{total}): {item['åŸå§‹æ–‡ä»¶å']}...")
                        r = requests.get(item['URL'], headers=headers, verify=False, timeout=60)
                        zf.writestr(item['åŸå§‹æ–‡ä»¶å'], r.content)
                        success_count += 1
                        time.sleep(1)
                    except Exception as e:
                        error_log.append(f"å¤±è´¥: {item['åŸå§‹æ–‡ä»¶å']}")
                        pass
                    progress_bar.progress((i + 1) / total)
            
            status_text.success(f"å®Œæˆï¼æˆåŠŸ: {success_count}, è·³è¿‡/å¤±è´¥: {len(error_log)}")
            if error_log:
                st.warning("ä»¥ä¸‹æ–‡ä»¶æœªä¸‹è½½ï¼ˆå¯èƒ½å¤ªå¤§ï¼‰ï¼š")
                st.write(error_log)
            
            progress_bar.empty()
            
            if success_count > 0:
                st.download_button(
                    label=f"ğŸš€ ä¸‹è½½ ZIP ({success_count} ä¸ªæ–‡ä»¶)",
                    data=zip_buffer.getvalue(),
                    file_name=f"OSINT_Files_{int(time.time())}.zip",
                    mime="application/zip",
                    type="primary"
                )
